# -*- coding: utf-8 -*-
"""Churn_Prediction_ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mJwTtgUmNocnbIItptxp-XeMi0dM_rfD

# Objective:
**The Ojective of this project is to build a model which can easily classify/predict customers who are inactive(Churn) or active(Not Churn) by using Machine Learning Algorithms.**
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings as wr
wr.filterwarnings('ignore')

from sklearn.feature_selection import RFE
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import xgboost
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
import sklearn.metrics as metrics

"""# 1. Data Extraction"""

df = pd.read_csv('/content/Churn_Modelling.csv')
df.head()

"""# 2. Data Audit or Data Check"""

df.shape

df.columns

df.dtypes

df.info()

"""# 3. Data Cleaning"""

# checking null values
df.isna().sum()

# checking duplicated records
df.duplicated().sum()

"""# 4. Exploratory Data Analysis"""

# Checking correlation on numerical features
df.select_dtypes(include='number').corr()

# visualizing correlation
plt.figure(figsize=(15,6))
sns.heatmap(df.select_dtypes(include='number').corr(),annot=True)
plt.title('Correlation Heatmap')
plt.show()

sns.pairplot(df)

num_df = df.select_dtypes(include=np.number)
cat_df = df.select_dtypes(include='object')

# Performing Univaraie Analysis
for col in num_df.columns:
    plt.figure(figsize=(6,4))
    sns.distplot(num_df[col])
    plt.show()

for col in cat_df.columns:
  print(cat_df[col].value_counts())

# Visualizing the Gender column vs Churn
P1 = df.groupby('Gender')['Exited'].value_counts()
print(P1)

plt.figure(figsize=(6,4))
sns.barplot(x='Gender',y='Exited',data=df)
plt.title('Gender vs Churn')
plt.xlabel('Gender')
plt.ylabel('Churn')
plt.show()

plt.figure(figsize=(6,4))
sns.barplot(x='Geography',y='Exited',hue='Gender',data=df)
plt.title('Geography vs Churn')
plt.xlabel('Geography')
plt.ylabel('Churn')
plt.show()

plt.figure(figsize=(6,4))
sns.countplot(x='Geography',hue='Gender',data=df)
plt.title('Geography vs Gender')
plt.xlabel('Geography')
plt.ylabel('Count')
plt.show()

num_df.drop(['RowNumber','CustomerId'],axis=1,inplace=True)
num_df.head()

# Checking Outliers using Boxplot
for col in num_df.columns:
  if col != 'Exited':
    plt.figure(figsize=(5,3))
    sns.boxplot(df[col])
    plt.show()

def outlier_treatment(x):
  q1 = x.quantile(0.25)
  q3 = x.quantile(0.75)
  iqr = q3-q1
  lower_bound = q1 - (1.5 * iqr)
  upper_bound = q3 + (1.5 * iqr)
  return x.clip(lower=lower_bound,upper=upper_bound)

cols = ['CreditScore','Age','NumOfProducts']

num_df[cols] = num_df[cols].apply(outlier_treatment)

# Checking Outliers using Boxplot
for col in num_df.columns:
  if col != 'Exited':
    plt.figure(figsize=(5,3))
    sns.boxplot(num_df[col])
    plt.show()

"""# 5. Data Preprocessing"""

# Encoding categorical features
le = LabelEncoder()
cat_df['Geography'] = le.fit_transform(cat_df['Geography'])
cat_df['Gender'] = le.fit_transform(cat_df['Gender'])

cat_df.head()

cat_df.drop('Surname',axis=1,inplace=True)

cat_df.head()

# Concatinating num_df & cat_df into one datafrme
data = pd.concat([num_df,cat_df],axis=1)

data.head()

# Split input features and out put feature
X = data.drop('Exited',axis=1)
y = data['Exited']

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)
X_train.shape,y_train.shape

"""# Model Implemantation

# I implement the following model
- Deciion Tree Classifier
- Random Forest Classifier
- XGBoost Classifier
"""

# Initialize the model
tree = DecisionTreeClassifier()
model = tree.fit(X_train,y_train)

# making model predictions
trian_pred = model.predict(X_train)
test_pred = model.predict(X_test)

# Model evaluation
print('Training Accuracy : ',metrics.accuracy_score(y_train,trian_pred))
print('Testing Accuracy : ',metrics.accuracy_score(y_test,test_pred))
#

# Confuion matrix on training set
metrics.confusion_matrix(y_train,trian_pred)

# Confusion matrix on testing set
metrics.confusion_matrix(y_test,test_pred)

# Classification report on training set
print(metrics.classification_report(y_train,trian_pred))

# Classification report on testng set
print(metrics.classification_report(y_test,test_pred))

"""# Implementing K-Fold Cross_Validation"""

cv_scores = cross_val_score(model,X,y,cv=5, scoring='accuracy')
print('Cross-validation scores:',cv_scores)
print('Mean Cv accuracy:',cv_scores.mean())

"""# Hyper tuning using GridsearchCV

"""

param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [3,5,7,10,15,None],
    'min_samples_split': [2,5,10,20],
    'min_samples_leaf': [1,2,5,10],
    'max_features': ['sqrt', 'log2', None]
}

grid_search = GridSearchCV(estimator=model,
                           param_grid=param_grid,
                           cv=5,
                           scoring='accuracy')
grid_search.fit(X_train,y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best Cross Validation Accuracy:", grid_search.best_score_)

"""# Decison Tree classifier model with optimal hyper parameters"""

model = DecisionTreeClassifier(criterion='entropy',
                               max_depth=5,
                               max_features=None,
                               min_samples_leaf=2,
                               min_samples_split=5
                               )
model.fit(X_train, y_train)

trainh_pred = model.predict(X_train)
testh_pred = model.predict(X_test)

# Model evaluation
print(metrics.accuracy_score(y_train,trainh_pred))
print(metrics.accuracy_score(y_test,testh_pred))

print(metrics.classification_report(y_train,trainh_pred))

print(metrics.classification_report(y_test,testh_pred))

train_accH = metrics.accuracy_score(y_train,trainh_pred)
test_accH = metrics.accuracy_score(y_test,testh_pred)

dt_importance = model.feature_importances_

for feature, score in zip(X.columns, dt_importance):
    print(feature, score)

"""# Building RandomForestClassifier Model"""

# Implemenation of RandomForest with default parameters
model1 = RandomForestClassifier()
model1.fit(X_train,y_train)

# Making predicitons
train_pred1 = model1.predict(X_train)
test_pred1 = model1.predict(X_test)

# Evaluation of RandomForest Model
print(metrics.accuracy_score(y_train,train_pred1))
print(metrics.accuracy_score(y_test,test_pred1))

print(metrics.classification_report(y_train,train_pred1))
print(metrics.classification_report(y_test,test_pred1))

# Random Forest Model Cross validation
cv_scores = cross_val_score(model1,X,y,cv=5,scoring='accuracy')
print('Cross-validation scores:',cv_scores)
print('Mean Cv accuracy:',cv_scores.mean())

# Hyper Tuning for Random Forest Model using GridSearchCV
param_grid = {
    'n_estimators': [50,200,150],
    'max_depth': [5, 10, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5],
    'max_features': ['sqrt', 'log2'],
    'bootstrap': [True, False]
}

rf = RandomForestClassifier(random_state=42)

grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best Cross Validation Accuracy:", grid_search.best_score_)

model1 = RandomForestClassifier(n_estimators= 200,
                                max_depth = 20 ,
                                min_samples_split= 2,
                                min_samples_leaf=5,
                                max_features='sqrt',
                                bootstrap =True,
                                oob_score=True)

model1.fit(X_train,y_train)

trainR_pred = model1.predict(X_train)
testR_pred = model1.predict(X_test)
#

# Model evaluation
print(metrics.accuracy_score(y_train,trainR_pred))
print(metrics.accuracy_score(y_test,testR_pred))

print(metrics.classification_report(y_train,trainR_pred))
print(metrics.classification_report(y_test,testR_pred))

"""# XGBoost Classifier model implementation"""

# Implementing XGboost model
model2 = XGBClassifier()
model2.fit(X_train,y_train)

# Making predictions
train_pred2 = model2.predict(X_train)
test_pred2 = model2.predict(X_test)

# Evaluation of xgboost model
print(metrics.accuracy_score(y_train,train_pred2))
print(metrics.accuracy_score(y_test,test_pred2))

print(metrics.classification_report(y_train,train_pred2))
print(metrics.classification_report(y_test,test_pred2))

# Hyper tuning for Xgboost model

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 6, 9],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'gamma': [0, 0.1, 0.3],
    'min_child_weight': [1, 3, 5]
}

grid_search = GridSearchCV(
    estimator=XGBClassifier(objective='binary:logistic', eval_metric='logloss'),
    param_grid=param_grid,
    scoring='accuracy',
    cv=5,
    n_jobs=-1,
    verbose=2
)

grid_search.fit(X_train, y_train)

grid_search.best_params_

grid_search.best_score_

"""# XGBClassifier using optimal hyper parameters"""

model3 = XGBClassifier(max_depth=6,
                       min_child_weight=3,
                       n_estimators=100,
                       learning_rate=0.05,
                       subsample=0.6,
                       coalsample_bytree = 0.8,
                       gamma=0)
model3.fit(X_train,y_train)

trainXH_pred = model3.predict(X_train)
testXH_pred = model3.predict(X_test)

# Model evaluation
print(metrics.accuracy_score(y_train,trainXH_pred))
print(metrics.accuracy_score(y_test,testXH_pred))

print(metrics.classification_report(y_train,trainXH_pred))
print(metrics.classification_report(y_test,testXH_pred))

Accuracy = pd.DataFrame()
Accuracy['Model'] = ['Decision Tree','Decision Tree Optimal','Random Forest','Random Forest Optimal','XGBoost','XGboost Optimal']
Accuracy['Train_Accuracy'] = [100,86,100,90,96,88]
Accuracy['Test_Accuracy'] = [78,86,87,86,86,87]
Accuracy

plt.figure(figsize=(10,4))
plt.plot('Model','Train_Accuracy',data=Accuracy)
plt.plot('Model','Test_Accuracy',data=Accuracy)
plt.show()

"""# Conclusion

Out of all models XGBoost model with optimal hyper parameters perform well on this dataset. XGBoost classifier with optimal hyper parameters got 88% in Training and 87% in Testing. Which is generalized model. So at the end XGBoost Classifier with best parameters is the best model.
"""

